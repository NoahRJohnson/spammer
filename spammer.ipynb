{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spammer: Harvesting emails and phone numbers\n",
    "Extract phone numbers and email addresses from web pages (HTML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Data is split into training and testing sets. Data consists of HTML files, with embedded e-mail addresses and phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = 'dev'\n",
    "TEST_FOLDER = 'test'\n",
    "TRAIN_LABELS_FILE = 'devGOLD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiken', 'ashishg', 'balaji', 'bgirod', 'cheriton', 'christos', 'dabo', 'dlwh', 'dm', 'engler', 'eroberts', 'fedkiw', 'hager', 'hanrahan', 'horowitz', 'jks', 'jurafsky', 'jure', 'knuth', 'koller', 'kosecka', 'kunle', 'lam', 'latombe', 'levoy', 'manning', 'nass', 'nick', 'nickm']\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(TRAIN_FOLDER)\n",
    "print(sorted(train_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the HTML files in our training set. Let's load all the raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary comprehension FTW\n",
    "train_data = {fn:open(os.path.join(TRAIN_FOLDER, fn), 'r').read() for fn in train_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, great. Now for each training file we have the raw HTML. Let's take a look at the training labels next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ashishg\te\tashishg@stanford.edu\n",
      "\n",
      "ashishg\te\trozm@stanford.edu\n",
      "\n",
      "ashishg\tp\t650-723-1614\n",
      "\n",
      "ashishg\tp\t650-723-4173\n",
      "\n",
      "ashishg\tp\t650-814-1478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_LABELS_FILE, 'r') as f:\n",
    "    for line in f.readlines()[:5]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our labels come in a white-space delimited file. From context we can tell that the first column is the training file, the second column is the type ('e' for email, 'p' for phone-number), and the third column is the extracted value. This is a good format for a pandas data frame, so let's load the label data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_name type                 value\n",
      "0   ashishg    e  ashishg@stanford.edu\n",
      "1   ashishg    e     rozm@stanford.edu\n",
      "2   ashishg    p          650-723-1614\n",
      "3   ashishg    p          650-723-4173\n",
      "4   ashishg    p          650-814-1478\n"
     ]
    }
   ],
   "source": [
    "train_labels = pd.read_csv(TRAIN_LABELS_FILE, delim_whitespace=True,\n",
    "                           header=None, names=['file_name','type','value'])\n",
    "print(train_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our model\n",
    "Let's start developing our algorithm. We will be using cascades of regular expressions. So instead of having a machine learning model automatically learn from the training data through some sort of optimization, I will manually update the model to fit the training data, and hopefully generalize to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our model\n",
    "Let's see how well the algorithm we've developed works on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
